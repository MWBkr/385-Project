---
title: "Data Transformations in R"
author: "Matthew Baker"
date: today
format: pdf
editor: source
---

```{r}
#| label: r setup
#| include: false
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, results = "hold")
library(tidyverse)
library(readr)
library(dplyr)
library(reticulate)
library(rvest)
library(xml2)
library(stringr)
library(timetk)
library(lubridate)
library(slider)
library(forecast)
library(tseries)
```

```{r}
Stock_Info <- read_csv("https://github.com/MWBkr/385-Project/releases/download/Data/Stock_Info.csv")
```

```{r}
Company_Info <- read_csv("https://raw.githubusercontent.com/MWBkr/385-Project/refs/heads/main/Company_Info.csv")
```

```{r}
# Step 1: Create monthly aggregates
cat("Original data size:", nrow(stock_growth), "rows\n")

stock_growth_monthly <- stock_growth %>%
    # Convert each date to the first day of its month
    mutate(year_month = floor_date(Date, "month")) %>%
    # Group by ticker + month to create monthly summaries
    group_by(Ticker, year_month) %>%
    # Sort so the last entry of each month is the closing price of that month
    arrange(Date) %>%
    # Take the final row of each month per ticker
    slice_tail(n = 1) %>%
    ungroup() %>%
    # Remove original daily Date column
    select(-Date) %>%
    # Rename the monthly timestamp back to "Date"
    rename(Date = year_month)

cat("Monthly aggregated size:", nrow(stock_growth_monthly), "rows\n")
```

```{r}
# Step 2: Calculate market capitalization and monthly rankings
monthly_rankings <- stock_growth_monthly %>%
    # Remove rows with missing price or volume
    filter(!is.na(Close) & !is.na(Volume)) %>%
    # Rough proxy for market cap = price * volume
    mutate(market_proxy = Close * Volume) %>%
    # Group by month so rankings are computed within each month
    group_by(Date) %>%
    mutate(
        # Rank descending; highest market cap proxy gets rank 1
        monthly_rank = rank(-market_proxy, ties.method = "first"),

        # Boolean flags for ranking thresholds
        in_top10 = monthly_rank <= 10,
        in_top5 = monthly_rank <= 5,
        in_top3 = monthly_rank <= 3
    ) %>%
    ungroup()

cat("Rankings calculated!\n")
```

```{r}
# Step 3: Identify milestone events
milestone_events <- monthly_rankings %>%
    # Work within each ticker so lag() checks previous month for same stock
    group_by(Ticker) %>%
    arrange(Date) %>%
    mutate(
        # TRUE only when entering top 10 from not being top 10 last month
        entered_top10 = in_top10 & !lag(in_top10, default = FALSE),

        # TRUE only when entering top 5
        entered_top5 = in_top5 & !lag(in_top5, default = FALSE),

        # TRUE only when entering top 3
        entered_top3 = in_top3 & !lag(in_top3, default = FALSE),

        # Extract year for summary reporting
        year = lubridate::year(Date)
    ) %>%
    # Keep only actual milestone events
    filter(entered_top10 | entered_top5 | entered_top3) %>%
    ungroup()

cat("Milestone events found:", nrow(milestone_events), "\n")
```

```{r}
# Step 3.5: Create 80/20 train-test split (time-based)
# Set seed for reproducibility
set.seed(123)

# Get unique dates and sort them
all_dates <- sort(unique(monthly_rankings$Date))
n_dates <- length(all_dates)

# Calculate 80% cutoff point
train_cutoff_index <- floor(n_dates * 0.8)
train_cutoff_date <- all_dates[train_cutoff_index]

# Split monthly_rankings into training period and testing period
monthly_rankings_train <- monthly_rankings %>%
    filter(Date <= train_cutoff_date)

monthly_rankings_test <- monthly_rankings %>%
    filter(Date > train_cutoff_date)

# Split milestone_events using the same date cutoff
milestone_events_train <- milestone_events %>%
    filter(Date <= train_cutoff_date)

milestone_events_test <- milestone_events %>%
    filter(Date > train_cutoff_date)

# Print split summary
cat("\n=== Train-Test Split Summary ===\n")
cat(
    "Training data date range:", as.character(min(monthly_rankings_train$Date)),
    "to", as.character(max(monthly_rankings_train$Date)), "\n"
)
cat(
    "Training data size:", nrow(monthly_rankings_train), "rows,",
    nrow(milestone_events_train), "milestone events\n"
)
cat(
    "Test data date range:", as.character(min(monthly_rankings_test$Date)),
    "to", as.character(max(monthly_rankings_test$Date)), "\n"
)
cat(
    "Test data size:", nrow(monthly_rankings_test), "rows,",
    nrow(milestone_events_test), "milestone events\n"
)
cat("Split ratio: ",
    round(nrow(monthly_rankings_train) / (nrow(monthly_rankings_train) + nrow(monthly_rankings_test)) * 100, 1),
    "% train / ",
    round(nrow(monthly_rankings_test) / (nrow(monthly_rankings_train) + nrow(monthly_rankings_test)) * 100, 1),
    "% test\n",
    sep = ""
)
```

```{r}
# Step 4: Define analysis function
analyze_milestone_impact <- function(full_data, milestone_data, milestone_col, months_before = 3, months_after = 6) {

    # Pull dates for this milestone type (top10, top5, or top3)
    milestone_dates <- milestone_data %>%
        filter(!!sym(milestone_col)) %>%
        select(Ticker, milestone_date = Date)

    full_data %>%
        # Join milestone events to full monthly dataset
        inner_join(milestone_dates, by = "Ticker", relationship = "many-to-many") %>%
        mutate(
            # Compute integer month difference from milestone
            months_from_milestone = interval(milestone_date, Date) %/% months(1)
        ) %>%
        # Restrict to the analysis window (e.g., −3 to +6 months)
        filter(months_from_milestone >= -months_before & months_from_milestone <= months_after) %>%
        # Summarize average/median returns for each month offset
        group_by(months_from_milestone) %>%
        summarise(
            avg_return = mean(pct_change, na.rm = TRUE),
            median_return = median(pct_change, na.rm = TRUE),
            count = n(),
            .groups = "drop"
        ) %>%
        # Label which milestone this result corresponds to
        mutate(milestone = milestone_col)
}

cat("Analysis function defined\n")
```

```{r}
# Step 5: Calculate impacts for top 10
cat("Analyzing top 10 milestone impact...\n")
top10_impact <- analyze_milestone_impact(monthly_rankings, milestone_events, "entered_top10")
cat("Top 10 analysis complete!\n")
```

```{r}
# Step 6: Calculate impacts for top 5
cat("Analyzing top 5 milestone impact...\n")
top5_impact <- analyze_milestone_impact(monthly_rankings, milestone_events, "entered_top5")
cat("Top 5 analysis complete!\n")
```

```{r}
# Step 7: Calculate impacts for top 3
cat("Analyzing top 3 milestone impact...\n")
top3_impact <- analyze_milestone_impact(monthly_rankings, milestone_events, "entered_top3")
cat("Top 3 analysis complete!\n")
```

```{r}
# Step 8: Combine all impacts
# Stack all milestone impact tables into one dataset
all_impacts <- bind_rows(top10_impact, top5_impact, top3_impact)
cat("All impacts combined!\n")
```

```{r}
# Step 9: Create milestone summary
milestone_summary <- milestone_events %>%
    # Convert milestone columns into long format
    pivot_longer(
        cols = c(entered_top10, entered_top5, entered_top3),
        names_to = "milestone", values_to = "occurred"
    ) %>%
    # Keep only rows where milestone occurred
    filter(occurred) %>%
    # Summaries within year + milestone type
    group_by(milestone, year) %>%
    summarise(
        events = n(),
        avg_return_on_day = mean(pct_change, na.rm = TRUE),
        median_return_on_day = median(pct_change, na.rm = TRUE),
        .groups = "drop"
    )

cat("\n=== Milestone Events Summary ===\n")
print(milestone_summary, n = 50)
```

```{r}
# Step 10: Display overall summary
cat("\n=== Overall Summary by Milestone Type ===\n")

# Same logic as above but summarizing across ALL years
milestone_events %>%
    pivot_longer(
        cols = c(entered_top10, entered_top5, entered_top3),
        names_to = "milestone", values_to = "occurred"
    ) %>%
    filter(occurred) %>%
    group_by(milestone) %>%
    summarise(
        total_events = n(),
        avg_return = mean(pct_change, na.rm = TRUE),
        median_return = median(pct_change, na.rm = TRUE),
        .groups = "drop"
    ) %>%
    print()

cat("\n=== Returns Around Milestones (by month) ===\n")
print(all_impacts, n = 30)
```

```{r}
# Visualize stock performance around milestone events (monthly window)
ggplot(all_impacts, aes(x = months_from_milestone, y = avg_return, color = milestone)) +
    # Line plot of average returns
    geom_line(size = 1) +
    geom_point() +
    # Vertical line at the milestone month (0)
    geom_vline(xintercept = 0, linetype = "dashed", color = "red", alpha = 0.7) +
    # Horizontal zero-return line
    geom_hline(yintercept = 0, linetype = "dotted", color = "gray") +
    labs(
        title = "Stock Performance Around S&P 500 Ranking Milestones",
        subtitle = "Average monthly returns before and after entering top tiers",
        x = "Months from Milestone Event",
        y = "Average Monthly Return (%)",
        color = "Milestone"
    ) +
    # Custom color palette
    scale_color_manual(
        values = c("entered_top10" = "#2E86AB", "entered_top5" = "#A23B72", "entered_top3" = "#F18F01"),
        labels = c("Entered Top 10", "Entered Top 5", "Entered Top 3")
    ) +
    # Clean theme
    theme_minimal() +
    theme(legend.position = "bottom")
```

```{r}
# Visualize milestone events by year
milestone_events %>%
    # Convert milestone columns into long format
    pivot_longer(
        cols = c(entered_top10, entered_top5, entered_top3),
        names_to = "milestone", values_to = "occurred"
    ) %>%
    filter(occurred) %>%
    # Count events per year + milestone type
    group_by(year, milestone) %>%
    summarise(events = n(), .groups = "drop") %>%
    ggplot(aes(x = year, y = events, color = milestone, fill = milestone)) +
    geom_col(position = "dodge", alpha = 0.7) +
    labs(
        title = "Frequency of S&P 500 Ranking Milestones Over Time",
        x = "Year",
        y = "Number of Events",
        color = "Milestone",
        fill = "Milestone"
    ) +
    # Same color scheme as earlier plot
    scale_color_manual(
        values = c("entered_top10" = "#2E86AB", "entered_top5" = "#A23B72", "entered_top3" = "#F18F01"),
        labels = c("Entered Top 10", "Entered Top 5", "Entered Top 3")
    ) +
    scale_fill_manual(
        values = c("entered_top10" = "#2E86AB", "entered_top5" = "#A23B72", "entered_top3" = "#F18F01"),
        labels = c("Entered Top 10", "Entered Top 5", "Entered Top 3")
    ) +
    theme_minimal() +
    theme(legend.position = "bottom")
```

```{r}
# Average returns on milestone entry day by year
milestone_events %>%
    pivot_longer(
        cols = c(entered_top10, entered_top5, entered_top3),
        names_to = "milestone", values_to = "occurred"
    ) %>%
    filter(occurred) %>%
    # For each year + milestone type, calculate average return
    group_by(year, milestone) %>%
    summarise(avg_return = mean(pct_change, na.rm = TRUE), .groups = "drop") %>%
    ggplot(aes(x = year, y = avg_return, color = milestone)) +
    geom_line(size = 1) +
    geom_point() +
    # Zero line for visual reference
    geom_hline(yintercept = 0, linetype = "dotted", color = "gray") +
    labs(
        title = "Average Stock Return on Milestone Entry Day",
        subtitle = "Performance trends over time",
        x = "Year",
        y = "Average Daily Return (%)",
        color = "Milestone"
    ) +
    scale_color_manual(
        values = c("entered_top10" = "#2E86AB", "entered_top5" = "#A23B72", "entered_top3" = "#F18F01"),
        labels = c("Entered Top 10", "Entered Top 5", "Entered Top 3")
    ) +
    theme_minimal() +
    theme(legend.position = "bottom")
```
#Exploratory Data Analysis
```{r}
#Split the columns into whether they are numeric or categorical
numeric_columns <- monthly_rankings %>% select(where(is.numeric)) %>% names()
categorical_columns <- monthly_rankings %>% select(where(~ is.character(.x) || is.factor(.x) || is.logical(.x))) %>% names()
```

```{r}
#Create output folder for CSVs/PNGs

outdir <- "eda_outputs"
if(!dir.exists(outdir)) dir.create(outdir)
{
  save_csv <- function(x, name)
  {
    readr::write_csv(
    tibble::as_tibble(x, rownames = NA) %>% tibble::rownames_to_column(".row") %>% relocate(.row),
    file.path(outdir, name))
  }
}
```

```{r}
#Checking numeric columns against numeric columns
if (length(numeric_columns) >= 2)
{
  num_mat <- monthly_rankings %>% select(all_of(numeric_columns))
  corr_p <- cor(num_mat, use = "pairwise.complete.obs", method = "pearson")
  corr_s <- cor(num_mat, use = "pairwise.complete.obs", method = "spearman")
  
  plot_corr <- function(cm, title_text)
  {
    cm_long <- as.data.frame(as.table(cm)) %>%
      rename(var1 = Var1, var2 = Var2, value = Freq)

    ggplot2::ggplot(cm_long, ggplot2::aes(var1, var2, fill = value)) +
      ggplot2::geom_tile() +
      ggplot2::scale_fill_gradient2(limits = c(-1, 1), midpoint = 0, name = NULL) +
      ggplot2::coord_equal() +
      ggplot2::labs(title = title_text, x = NULL, y = NULL) +
      ggplot2::theme_minimal() +
      ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 90, vjust = 0.5, hjust = 1),
                     plot.title = ggplot2::element_text(face = "bold"))

  }

  p1 <- plot_corr(corr_p, "Pearson correlation (numeric)")
  p2 <- plot_corr(corr_s, "Spearman correlation (numeric)")

  p1; p2

  ggplot2::ggsave(file.path(outdir, "corr_numeric_pearson.png"), p1, width = 8, height = 6, dpi = 150)
  ggplot2::ggsave(file.path(outdir, "corr_numeric_spearman.png"), p2, width = 8, height = 6, dpi = 150)
}
```

```{r}
#Checking categorical columns against categorical columns

cramers_v <- function(x, y)
{
  tbl <- table(x, y)
  if(nrow(tbl) < 2 || ncol(tbl) < 2)
  {
    return(NA_real_)
  }
  suppressWarnings(
  {
    chi <- suppressWarnings(chisq.test(tbl, correct = FALSE)$statistic)
    n <- sum(tbl)
    r <- nrow(tbl); k <- ncol(tbl)
    v <- sqrt(as.numeric(chi) / n / min(r - 1, k - 1))
    v
  })
}

#Limits high-cardinality columns for tractability

max_levels <- 40L
categorical_usable <- categorical_columns[vapply(monthly_rankings[categorical_columns], function(v) n_distinct(v, na.rm = F) <= max_levels, logical(1))]

if(length(categorical_usable) >= 2)
{
  cv_mat <- matrix(NA_real_, nrow = length(categorical_usable), ncol = length(categorical_usable), dimnames = list(categorical_usable, categorical_usable))
  for(i in seq_along(categorical_usable))
  {
    for(j in i:length(categorical_usable))
    {
      v <- cramers_v(monthly_rankings[[categorical_usable[i]]], monthly_rankings[[categorical_usable[j]]])
      cv_mat[i, j] <- cv_mat[j,i] <- v
    }
  }


  save_csv(cv_mat, "cramers_v_categorical.csv")

  cv_long <- as.data.frame(as.table(cv_mat)) %>%
    rename(var1 = Var1, var2 = Var2, value = Freq)

  p_cv <- ggplot2::ggplot(cv_long, ggplot2::aes(var1, var2, fill = value)) +
  ggplot2::geom_tile() +
  ggplot2::scale_fill_gradient(low = "#f0f0f0", high = "#1f77b4", na.value = "white", name = NULL) +
  ggplot2::coord_equal() +
  ggplot2::labs(title = "Cramér’s V (categorical)", x = NULL, y = NULL) +
  ggplot2::theme_minimal() +
  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 90, vjust = 0.5, hjust = 1),
  plot.title = ggplot2::element_text(face = "bold"))
  p_cv

  ggplot2::ggsave(file.path(outdir, "cramers_v_categorical.png"), p_cv, width = 8, height = 6, dpi = 150)
}
```

```{r}
#Checking categorical columns versus numerical columns

eta2 <- function(y, x)
{
  ok <- stats::complete.cases(y, x)
  y <- y[ok]; x <- x[ok]
  if(!length(y))
  {
    return(NA_real_)
  }
  grand <- mean(y)
  ss_t <- sum((y - grand)^2)
  if(ss_t == 0)
  {
    return(NA_real_)
  }
  g <- tapply(y, x, function(z) c(n = length(z), m = mean(z)))
  n <- vapply(g, function(u) u[["n"]], numeric(1))
  m <- vapply(g, function(u) u[["m"]], numeric(1))
  ss_b <- sum(n * (m - grand)^2)
  as.numeric(ss_b / ss_t)
}

numeric_usable <- numeric_columns
categorical_usable <- categorical_columns[
  vapply(
    monthly_rankings[categorical_columns],
    function(v) n_distinct(v, na.rm = FALSE) <= 60L,
    logical(1)
  )
]

if(length(numeric_usable) >= 1 && length(categorical_usable) >= 1)
{
  eta_grid <- purrr::map_dfr(categorical_usable, function(cc)
    {
      # Use an explicit function so 'cc' is captured properly
      vals <- purrr::map_dbl(numeric_usable, function(nc)
      {
        eta2(monthly_rankings[[nc]], monthly_rankings[[cc]])
      })
      tibble::tibble(
        categorical = cc,
        !!! rlang::set_names(as.list(vals), numeric_usable)  # splice named columns
      )
    })

  readr::write_csv(eta_grid, file.path(outdir, "eta2_categorical_numeric.csv"))

  eta_long <- eta_grid %>%
    pivot_longer(-categorical, names_to = "numeric", values_to = "eta2") %>%
    arrange(desc(eta2)) %>%
    filter(!is.na(eta2))

  top_pairs <- eta_long %>%
    slice_head(n = 20)

  readr::write_csv(top_pairs, file.path(outdir, "eta2_top_pairs.csv"))

  top_pairs %>%
    mutate(eta2 = round(eta2, 3)) %>%
    knitr::kable(caption = "Top 20 categorical -> numerical associations (η²)")
}
```


#Sliding Window
```{r}

```


